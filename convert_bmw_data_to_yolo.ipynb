{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import struct\n",
    "import shutil\n",
    "\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "destination_folder = \"yolov5_data\"\n",
    "\n",
    "subfolders = [\"Regensburg_Plant\"]\n",
    "\n",
    "proportions = {\n",
    "    \"train\": 80,\n",
    "    \"val\": 10,\n",
    "    \"test\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating dir: \", destination_folder)\n",
    "\n",
    "dataset_imgs_train_p = os.path.join(destination_folder, 'images', 'train')\n",
    "dataset_imgs_val_p = os.path.join(destination_folder, 'images', 'val')\n",
    "dataset_imgs_test_p = os.path.join(destination_folder, 'images', 'test')\n",
    "dataset_labels_train_p = os.path.join(destination_folder, 'labels', 'train')\n",
    "dataset_labels_val_p = os.path.join(destination_folder, 'labels', 'val')\n",
    "dataset_labels_test_p = os.path.join(destination_folder, 'labels', 'test')\n",
    "os.makedirs(destination_folder, exist_ok = True)\n",
    "os.makedirs(dataset_imgs_train_p, exist_ok = True)\n",
    "os.makedirs(dataset_imgs_val_p, exist_ok = True)\n",
    "os.makedirs(dataset_imgs_test_p, exist_ok = True)\n",
    "os.makedirs(dataset_labels_train_p, exist_ok = True)\n",
    "os.makedirs(dataset_labels_val_p, exist_ok = True)\n",
    "os.makedirs(dataset_labels_test_p, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(file_path):\n",
    "    \"\"\"\n",
    "    Return (width, height) for a given img file content - no external\n",
    "    dependencies except the os and struct modules from core\n",
    "    \"\"\"\n",
    "    size = os.path.getsize(file_path)\n",
    "\n",
    "    with open(file_path, 'rb') as input:\n",
    "        height = -1\n",
    "        width = -1\n",
    "        data = input.read(25)\n",
    "        #data = str(data\n",
    "        #data = data.decode('utf-8')\n",
    "        #data = bytes(data)\n",
    "        #print(data)\n",
    "        if True:\n",
    "            input.seek(0)\n",
    "            input.read(2)\n",
    "            b = input.read(1)\n",
    "            while (b and ord(b) != 0xDA):\n",
    "                while (ord(b) != 0xFF): b = input.read(1)\n",
    "                while (ord(b) == 0xFF): b = input.read(1)\n",
    "                if (ord(b) >= 0xC0 and ord(b) <= 0xC3):\n",
    "                    input.read(3)\n",
    "                    h, w = struct.unpack(\">HH\", input.read(4))\n",
    "                    break\n",
    "                else:\n",
    "                    input.read(int(struct.unpack(\">H\", input.read(2))[0])-2)\n",
    "                b = input.read(1)\n",
    "            width = int(w)\n",
    "            height = int(h)\n",
    "            return width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2path = {}\n",
    "\n",
    "all_classes = []\n",
    "all_classes_set = []\n",
    "fileindex = 0\n",
    "\n",
    "if isinstance(subfolders, list):\n",
    "    folders = subfolders \n",
    "else:\n",
    "    folders = os.listdir(data_folder)\n",
    "\n",
    "for folder in folders:\n",
    "    # print(folder)\n",
    "    folder_path = os.path.join(data_folder, folder)\n",
    "    if not os.path.isdir(folder_path):        \n",
    "        continue\n",
    "    print(os.path.join(folder_path, 'objectclasses.json'))\n",
    "    a = time.time()\n",
    "    with open(os.path.join(folder_path, 'objectclasses.json'), 'r') as clsf:\n",
    "        classes = json.load(clsf)\n",
    "    for objclass in classes:\n",
    "        if objclass not in all_classes:\n",
    "            all_classes.append(objclass)\n",
    "        objname = objclass['Name']\n",
    "        if objname not in all_classes_set:\n",
    "            all_classes_set.append(objname)\n",
    "    # print(all_classes)\n",
    "    # print(all_classes_set)\n",
    "    files = os.listdir(os.path.join(folder_path, 'images'))\n",
    "    # print(files)\n",
    "    for img_name in files:\n",
    "        import random\n",
    "        assigned = random.choices([\"train\", \"val\", \"test\"], weights=(proportions[\"train\"], proportions[\"val\"], proportions[\"test\"]), k=1)\n",
    "        b = time.time()\n",
    "        img_path = os.path.join(folder_path, 'images', img_name)\n",
    "        # print(\"Image Path: \", img_path)\n",
    "        label_path = os.path.join(folder_path, 'labels', 'json', img_name.replace('jpg', 'json'))\n",
    "        # print(\"Label path: \", label_path)\n",
    "        if os.path.exists(img_path):\n",
    "            print(img_path)\n",
    "            source_image = img_path\n",
    "            new_image_name = f\"{folder}_{img_name}\"\n",
    "            print(new_image_name)\n",
    "            destination_image = os.path.join(destination_folder, 'images', assigned[0], new_image_name)\n",
    "            shutil.copyfile(source_image, destination_image)\n",
    "            # shutil.copyfile(src_l, dst_l)\n",
    "    #     #if not os.path.exists(os.path.join(dataset_imgs_train_p, str(fileindex) + '.jpg')):\n",
    "    #     #    os.symlink(os.path.abspath(p_img), os.path.join(dataset_imgs_train_p, str(fileindex) + '.jpg'))\n",
    "    #     #print(p_img)\n",
    "    #     split = p_img.split('/')\n",
    "    #     id2path[fileindex] = split[-3] + ',' + split[-1]\n",
    "        w, h = get_image_size(img_path)\n",
    "        with open(label_path, 'r') as annotation_file:\n",
    "            annotations = json.load(annotation_file)\n",
    "        dupcheck = []\n",
    "        with open(os.path.join(destination_folder, 'labels', assigned[0], new_image_name.replace('.jpg', '') + '.txt'), 'w') as txtf:\n",
    "            for anno in annotations:\n",
    "                yolo_class_index = all_classes_set.index(anno['ObjectClassName'])\n",
    "                right, left, top, bottom = anno['Right'], anno['Left'], anno['Top'], anno['Bottom']\n",
    "                x_center = ((left + right) / 2) / w\n",
    "                y_center = ((top + bottom) / 2) / h\n",
    "                w_normalized = (right - left) / w\n",
    "                h_normalized = (bottom - top) / h\n",
    "                area = (right - left) * (bottom - top)\n",
    "                if area < 400:\n",
    "                    continue\n",
    "\n",
    "                yololine = str(yolo_class_index) + ' ' + str(x_center) + ' ' + str(y_center) + ' ' + str(w_normalized) + ' ' + str(h_normalized)\n",
    "                if yololine in dupcheck:\n",
    "                    continue\n",
    "                dupcheck.append(yololine)\n",
    "                txtf.write(yololine)\n",
    "                txtf.write('\\n')\n",
    "        c = time.time()\n",
    "    d = time.time()\n",
    "\n",
    "with open(os.path.join(destination_folder, 'sordi.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_classes, f, ensure_ascii=False, indent=4)\n",
    "    # print('folder:', (d-a))\n",
    "\n",
    "with open(os.path.join(destination_folder, 'sordi.yaml'), 'w', encoding='utf-8') as f:\n",
    "    f.write('path: ./sordi\\n')\n",
    "    f.write('train: images/train\\n')\n",
    "    f.write('val: images/val\\n')\n",
    "    f.write('test: images/test\\n')\n",
    "    f.write('names:\\n')\n",
    "    index = 0\n",
    "    for anno_class in all_classes_set:\n",
    "        f.write('  ' + str(index) + ': ' + anno_class + '\\n')\n",
    "        index += 1\n",
    "\n",
    "with open(os.path.join(destination_folder, 'dataset.yaml'), 'w', encoding='utf-8') as f:\n",
    "    f.write('path: .\\n')\n",
    "    f.write('train: ./images/train\\n')\n",
    "    f.write('val: ./images/val\\n')\n",
    "    f.write('test: ./images/test\\n')\n",
    "    f.write(f'nc: {len(all_classes_set)}\\n')\n",
    "    f.write('names: [')\n",
    "    index = 0\n",
    "    for anno_class in all_classes_set:\n",
    "        if anno_class == all_classes_set[-1]:\n",
    "            f.write('\"' + anno_class + '\"')\n",
    "        else:\n",
    "            f.write('\"' + anno_class + '\",')\n",
    "    f.write(']')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
